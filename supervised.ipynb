{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB, CategoricalNB\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('C:/CUB/sem2/ml/proj/CN_Dataset/cleaned_data.csv')\n",
    "# Separate features and target\n",
    "X = df.drop('SuggestedJobRole', axis=1)\n",
    "y = df['SuggestedJobRole']\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 21 columns):\n",
      " #   Column                               Non-Null Count  Dtype \n",
      "---  ------                               --------------  ----- \n",
      " 0   SuggestedJobRole                     10000 non-null  object\n",
      " 1   keywords                             10000 non-null  object\n",
      " 2   Logical quotient rating              10000 non-null  int64 \n",
      " 3   hackathons                           10000 non-null  int64 \n",
      " 4   coding skills rating                 10000 non-null  int64 \n",
      " 5   public speaking points               10000 non-null  int64 \n",
      " 6   self-learning capability?            10000 non-null  object\n",
      " 7   Extra-courses did                    10000 non-null  object\n",
      " 8   certifications                       10000 non-null  object\n",
      " 9   workshops                            10000 non-null  object\n",
      " 10  reading and writing skills           10000 non-null  object\n",
      " 11  memory capability score              10000 non-null  object\n",
      " 12  Interested subjects                  10000 non-null  object\n",
      " 13  interested career area               10000 non-null  object\n",
      " 14  Type of company want to settle in?   10000 non-null  object\n",
      " 15  Taken inputs from seniors or elders  10000 non-null  object\n",
      " 16  Interested Type of Books             10000 non-null  object\n",
      " 17  Management or Technical              10000 non-null  object\n",
      " 18  hard/smart worker                    10000 non-null  object\n",
      " 19  worked in teams ever?                10000 non-null  object\n",
      " 20  Introvert                            10000 non-null  object\n",
      "dtypes: int64(4), object(17)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vbhav\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "c:\\Users\\vbhav\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MultinomialNB ===\n",
      "Accuracy: 0.3440\n",
      "\n",
      "=== BernoulliNB ===\n",
      "Accuracy: 0.3390\n",
      "\n",
      "=== CategoricalNB ===\n",
      "Accuracy: 0.2587\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB, CategoricalNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "# 1) Load Data\n",
    "df = pd.read_csv('C:/CUB/sem2/ml/proj/CN_Dataset/cleaned_data.csv')\n",
    "\n",
    "# 2) Fix Non-Numeric Columns Used in \"numeric_features\"\n",
    "score_map = {\"poor\": 1, \"medium\": 2, \"excellent\": 3}\n",
    "df[\"memory capability score\"] = df[\"memory capability score\"].map(score_map)\n",
    "df[\"public speaking points\"] = df[\"public speaking points\"].astype(int)\n",
    "\n",
    "# 3) Separate Target\n",
    "y = df[\"SuggestedJobRole\"]\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# 4) MultinomialNB\n",
    "vectorizer_multinomial = CountVectorizer(tokenizer=lambda x: x.split(\", \"))\n",
    "X_keywords_counts = vectorizer_multinomial.fit_transform(df[\"keywords\"])\n",
    "\n",
    "numeric_features = [\n",
    "    \"Logical quotient rating\", \n",
    "    \"hackathons\", \n",
    "    \"coding skills rating\", \n",
    "    \"public speaking points\", \n",
    "    \"memory capability score\"\n",
    "]\n",
    "X_numeric = df[numeric_features]\n",
    "X_multinomial = hstack([X_keywords_counts, X_numeric])\n",
    "\n",
    "X_train_multi, X_test_multi, y_train_multi, y_test_multi = train_test_split(\n",
    "    X_multinomial, y_encoded, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train_multi, y_train_multi)\n",
    "y_pred_multi = mnb.predict(X_test_multi)\n",
    "print(\"=== MultinomialNB ===\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test_multi, y_pred_multi):.4f}\")\n",
    "\n",
    "\n",
    "# 5) BernoulliNB\n",
    "vectorizer_bernoulli = CountVectorizer(tokenizer=lambda x: x.split(\", \"), binary=True)\n",
    "X_keywords_binary = vectorizer_bernoulli.fit_transform(df[\"keywords\"])\n",
    "\n",
    "binary_cols = [\n",
    "    \"self-learning capability?\", \n",
    "    \"Extra-courses did\", \n",
    "    \"worked in teams ever?\", \n",
    "    \"Introvert\"\n",
    "]\n",
    "df_binary = df[binary_cols].copy()\n",
    "for col in binary_cols:\n",
    "    df_binary[col] = df_binary[col].map({\"yes\": 1, \"no\": 0})\n",
    "\n",
    "X_bernoulli = hstack([X_keywords_binary, df_binary])\n",
    "\n",
    "X_train_bern, X_test_bern, y_train_bern, y_test_bern = train_test_split(\n",
    "    X_bernoulli, y_encoded, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(X_train_bern, y_train_bern)\n",
    "y_pred_bern = bnb.predict(X_test_bern)\n",
    "print(\"\\n=== BernoulliNB ===\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test_bern, y_pred_bern):.4f}\")\n",
    "\n",
    "\n",
    "# 6) CategoricalNB\n",
    "categorical_cols = [\n",
    "    \"Interested subjects\", \n",
    "    # \"interested career area\",  # removed if not in df.columns\n",
    "    \"Type of company want to settle in?\",\n",
    "    \"Interested Type of Books\", \n",
    "    \"Management or Technical\", \n",
    "    \"hard/smart worker\",\n",
    "    \"certifications\", \n",
    "    \"workshops\", \n",
    "    \"reading and writing skills\"\n",
    "]\n",
    "df_cat = df[categorical_cols].copy()\n",
    "for col in categorical_cols:\n",
    "    df_cat[col] = LabelEncoder().fit_transform(df_cat[col])\n",
    "\n",
    "X_train_cat, X_test_cat, y_train_cat, y_test_cat = train_test_split(\n",
    "    df_cat, y_encoded, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "catnb = CategoricalNB()\n",
    "catnb.fit(X_train_cat.values, y_train_cat)\n",
    "y_pred_cat = catnb.predict(X_test_cat.values)\n",
    "print(\"\\n=== CategoricalNB ===\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test_cat, y_pred_cat):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
